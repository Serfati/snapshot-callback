{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"aml-snapshot.ipynb","provenance":[],"authorship_tag":"ABX9TyPptLsCpy7JPezcsIrGmQyK"},"kernelspec":{"name":"python3","display_name":"Python 3.9.5 64-bit"},"language_info":{"name":"python","version":"3.9.5"},"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# %cd drive/MyDrive/aml4"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Ignore  the warnings\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.metrics import fbeta_score, make_scorer\n","\n","# scoring\n","from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score,auc, classification_report"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from matplotlib import style\n","from collections import defaultdict\n","# configure\n","# sets matplotlib to inline and displays graphs below the corressponding cell.\n","%matplotlib inline\n","style.use('fivethirtyeight')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from snapshots.snapshot_ens import *\n","from baseline.baseline import Baseline\n","from improve_snapshot.swa.tfkeras import SWA"]},{"source":["# HELPERS"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def model_fit_with_grid_search_nested_cv(model,parameters,fit_params, X, y, df_name, round, folds = 10, score = 'accuracy', verbose = 0 ):\n","\n","    start = time.time()\n","\n","    cv_inner = StratifiedKFold(n_splits=int(folds/3), shuffle=True, random_state=1)\n","    cv_outer = StratifiedKFold(n_splits=folds, shuffle=True, random_state=1)\n","\n","    clf = GridSearchCV(\n","        estimator = model,\n","        param_grid = parameters,\n","        cv = cv_inner,\n","        scoring = score, \n","        verbose = verbose,\n","        n_jobs = 1,\n","        refit=True\n","    )\n","\n","    # Non-nested parameter search and scoring\n","    clf.fit(X, y)\n","    outer_scores[i] = clf.best_score_\n","    nested_score = cross_val_score(clf, X, y, scoring=score, cv=cv_outer, n_jobs=-1, fit_params=fit_params)\n","    nested_scores[i] = nested_score.mean()\n","\n","    if verbose > 0:\n","        print(\"--- Ellapsed time: %s seconds ---\" % (time.time() - start))\n","        print('Best params: ',clf.best_params_)\n","        print('Best score (%s)' % nested_score, clf.best_score_)\n","        print('%s Nested Cross Validation Accuracy: %.3f (%.3f)' % (df_name, np.mean(nested_score),                                                                             np.std (nested_score)))\n","    return clf.best_estimator_, clf.best_params_, clf.best_score_, outer_scores, nested_scores, time.time() - start"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def plot_nested_cv(model_name, nested_scores, outer_scores):\n","    # Plot scores on each trial for nested and non-nested cross-validation\n","    plt.style.use('seaborn')\n","    plt.tight_layout()\n","    plt.figure(figsize=(10,5))\n","    outer_scores_line, = plt.plot(outer_scores, color='orange')\n","    nested_line, = plt.plot(nested_scores, color='steelblue')\n","    plt.ylabel(\"Score\", fontsize=\"14\")\n","    plt.legend([outer_scores_line, nested_line],\n","            [\"Non-Nested CV\", \"Nested CV\"],\n","            bbox_to_anchor=(0, .4, .5, 0))\n","    plt.title(\"Non-Nested vs Nested Cross-Validation using \"+model_name,\n","            x=.5, y=1.1, fontsize=\"15\")\n","    # Save the plot\n","    plt.savefig(\"nested-vs-non-nested.png\", dpi=150)\n","    #Take the difference from the non-nested and nested scores\n","    score_difference = outer_scores - nested_scores\n","\n","    print(\"Avg. difference of {:6f} with std. dev. of {:6f}.\"\n","        .format(score_difference.mean(), score_difference.std()))"]},{"source":["# TRAINING"],"cell_type":"markdown","metadata":{}},{"source":["# EVALUATION HELPERS"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def predict(model,X,y):\n","    df_result = pd.DataFrame(columns = ['TrueClass','Predicted'])\n","    df_result.Predicted = model.predict(X)\n","    df_result.TrueClass = y.values.ravel()\n","    return df_result"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def plot_confusion_matrix(df,title,labels = ['Negative', 'Positive'],dataset_type = 'Test'):\n","    conf_matrix = confusion_matrix(df.TrueClass, df.Predicted)\n","    plt.figure(figsize=(8, 8))\n","    sns.heatmap(conf_matrix, xticklabels=labels, yticklabels=labels, annot=True, fmt=\"d\");\n","    plt.title('{0} - Confusion matrix - {1} set'.format(title,dataset_type), fontsize = 20)\n","    plt.xlabel('Predicted class')\n","    plt.ylabel('True class')\n","    plt.show()\n","    return conf_matrix.ravel()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def evalute_model_performance(model, model_name, X, y, df_name='none'):\n","    df_result = predict(model,X,y)\n","    class_report = classification_report(df_result.TrueClass, df_result.Predicted, output_dict= True)\n","    accuracy = class_report['accuracy']\n","    recall = class_report['macro avg']['recall']\n","    precision = class_report['macro avg']['precision']\n","    auc_pr = round(auc(recall, precision),2)\n","    f1 = class_report['macro avg']['f1-score']\n","    f2 = fbeta_score(df_result.TrueClass, df_result.Predicted,beta = 2, average='macro')\n","\n","    naive_probs = [0 for _ in range(len(y))]\n","    \n","    probs = model.predict_proba(X)\n","    probs = probs[:, 1]\n","\n","    naive_auc = roc_auc_score(y, naive_probs)\n","    model_auc = roc_auc_score(y, probs)\n","\n","    print('No Skill: ROC AUC=%.3f' % (naive_auc))\n","    print(model_name,': ROC AUC=%.3f' % (model_auc))\n","\n","    naive_fpr, naive_tpr, _ = roc_curve(y, naive_probs)\n","    model_fpr, model_tpr, _ = roc_curve(y, probs)\n","\n","    print('')\n","    print('Performance Report: ')\n","\n","    print('Accuracy: %1.3f' % accuracy) #a\n","    print('TPR: %1.3f' % model_tpr) #b\n","    print('FPR: %1.3f' % model_fpr) #c\n","    print('Precision: %1.3f' % precision) #d\n","    print('AUC: %1.3f' % model_auc) #e\n","    print('AUC-PR: %1.3f' % auc_pr) #f\n","    print('Recall: %1.3f' % recall)\n","    print('F1: %1.3f' % f1)\n","    print('F2: %1.3f' % f2)\n","\n","    print('')\n","\n","    plot_confusion_matrix(df_result, model_name)\n","\n","    try:\n","        plot_ROC(model, model_name, model_fpr, model_tpr, naive_fpr, naive_tpr)\n","    except:\n","        print('Could not print ROC AUC curve.')\n","    new_row = {\"Dataset Name\":df_name, \"Algorithm Name\":model_name, \"Cross Validation\":1, \"Hyper-Parameters Values\":0.5, \"Accuracy\":accuracy, \"TPR\":model_tpr, \"FPR\":model_fpr, \"Precision\":precision, \"AUC\":auc, \"AUC-PR\":auc_pr, \"Train Time\":5.32, \"Inference Time\":0.2}\n","    EVAL_DF = EVAL_DF.append(new_row, ignore_index=True)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def plot_ROC(model,model_name, model_fpr, model_tpr, naive_fpr, naive_tpr):\n","    plt.plot(naive_fpr, naive_tpr, linestyle='--', label='Naive')\n","    plt.plot(model_fpr, model_tpr, marker='.', label=model_name)\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def run_training_main_loop(X, y, df_name, rounds):\n","    if not init_models_and_params(X, y): exit(1)\n","    \n","    print('='*20,df_name,20*'=')\n","    for i,model in enumerate(models_to_run):\n","        model_name = model.__class__.__name__+' '+str(i)   \n","        print('='*10,model_name,10*'=')\n","        \n","        #Clear scores arrays\n","        outer_scores = np.zeros(rounds)\n","        nested_scores = np.zeros(rounds)\n","        \n","        for _round in range(rounds):\n","            best_model,best_model_params,best_model_score, outer_scores, nested_scores, et = model_fit_with_grid_search_nested_cv( model,\n","                                                    models_param_grid[i],\n","                                                    fit_params,\n","                                                    X,\n","                                                    y,\n","                                                    df_name,\n","                                                    folds = 10,\n","                                                    score = 'accuracy',\n","                                                    round = _round, \n","                                                    verbose = 0\n","                                                )\n","\n","            best_models_dict[i].append((best_model,best_model_params, best_model_score, outer_scores, nested_scores, et))\n","            # inner loop\n","        plot_nested_cv(model_name, nested_scores, outer_scores)\n","        print('ยง'*10,model_name,10*'ยง')\n","    print('ยง'*30,df_name,30*'ยง')    "]},{"source":["# CALLBACKS"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["log_dir = \"logs/fit/\" + pd.datetime.now().strftime(\"%H%M%S\")\n","\n","tensor_board = TensorBoard(\n","    log_dir=log_dir, histogram_freq=0, write_graph=True,\n","    write_images=True, update_freq='epoch', profile_batch=2,\n","    embeddings_freq=0, embeddings_metadata=None\n",")\n","\n","# define snapshot callback\n","snp = Snapshot('snapshots', nb_epochs=6, verbose=1, nb_cycles=2)\n","\n","epochs = 50\n","start_epoch = epochs//2\n","\n","# define swa callback\n","swa = SWA(start_epoch=start_epoch, \n","          lr_schedule='constant', \n","          swa_lr=0.01, \n","          verbose=1)\n","\n","callbacks = [\n","             ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n","             EarlyStopping(monitor='val_acc', min_delta=1e-6, patience=15),\n","             tensor_board,\n","             snp,\n","             swa\n","             ]"]},{"source":["# MAIN"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#Number of rounds\n","rounds = 50\n","\n","#Create arrays to store the scores\n","outer_scores = np.zeros(rounds)\n","nested_scores = np.zeros(rounds)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["column_names = [\"Dataset Name\", \"Algorithm Name\", \"Cross Validation\",\"Hyper-Parameters Values\", \"Accuracy\", \"TPR\", \"FPR\", \"Precision\", \"AUC\", \"AUC-PR\", \"Training\", \"Train Time\", \"Inference Time\"]\n","EVAL_DF = pd.DataFrame(columns = column_names)"]},{"source":["# DATASETS"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["datasets_dict = defaultdict(list)\n","ds = os.listdir('datasets')[:10]\n","\n","for df_name in ds:\n","    # make dataset\n","    df = pd.read_csv('datasets/%s' % df_name)\n","    X, y = df.iloc[:, :-1], df.iloc[:, -1]\n","    y = to_categorical(y)\n","    datasets_dict[df_name[:-4]] = (X, y)"]},{"source":["# MODELING"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["models_to_run = []\n","models_param_grid = []\n","fit_params = {}\n","best_models_dict = defaultdict(list)\n","optimizer = SGD(lr=0.1, momentum=0.9, nesterov=True)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def init_models_and_params(X, y):        \n","        models_to_run = [\n","                Baseline(x_in=X.shape[1], x_out=len(y.unique())).baseline(),\n","                Baseline(x_in=X.shape[1], x_out=len(y.unique())).baseline(),\n","                Baseline(x_in=X.shape[1], x_out=len(y.unique())).baseline() \n","                ]\n","\n","        models_param_grid = [ \n","                        { # 1st param grid, corresponding to Baseline \n","                                'max_depth': [3, None],\n","                                'n_estimators': [100,200,300,400,500,600,700,800,900,1000],\n","                                'max_features' : [50,100,150,200]\n","                        }, \n","                        { # 2nd param grid, corresponding to Snapshot-ensamble\n","                                'learning_rate': [0.05],\n","                                'colsample_bytree': np.linspace(0.3, 0.5),\n","                                'n_estimators': [100,200,300,400,500,600,700,800,900,1000],\n","                                'reg_alpha' : (1,1.2),\n","                                'reg_lambda' : (1,1.2,1.4)\n","                        },\n","                        { # 3rd param grid, corresponding to Keras-SWA\n","                                'learning_rate': [0.05],\n","                                'n_estimators': [100,200,300,400,500,600,700,800,900,1000],\n","                                'reg_alpha' : (1,1.2),\n","                                'reg_lambda' : (1,1.2,1.4)\n","                        }\n","                        ]\n","\n","        fit_params = {'epochs': epochs, 'callbacks': callbacks, 'verbose': 1}\n","        return len(models_to_run) == 3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# main loop\n","[run_training_main_loop(X, y, df_name, rounds) for df_name, (X, y) in datasets_dict.items()]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del model\n","print('Loading ensemble...')\n","keep_last = 2\n","model = load_ensemble('snapshots')\n","model.compile(\n","    optimizer=SGD(lr=0.1, momentum=0.9, nesterov=True),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","metrics = model.evaluate(x_test, y_test)\n","print(metrics)"]}]}